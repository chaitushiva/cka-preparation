1) https://github.com/kubernetes/kubernetes/issues/96858
2) https://www.digitalocean.com/community/tutorials/how-to-inspect-kubernetes-networking
The second is a pause container running in the hello-world pod. This container exists solely to hold onto the pod’s network namespace
docker ps
Output
CONTAINER ID        IMAGE                                   COMMAND                  CREATED             STATUS              PORTS               NAMES
173ee46a3926        gcr.io/google-samples/node-hello        "/bin/sh -c 'node se…"   9 days ago          Up 9 days                               k8s_hello-world_hello-world-5b446dd74b-pxtzt_default_386a9073-7e35-11e8-8a3d-bae97d2c1afd_0
11ad51cb72df        k8s.gcr.io/pause-amd64:3.1              "/pause"                 9 days ago          Up 9 days                               k8s_POD_hello-world-5b446dd74b-pxtzt_default_386a9073-7e35-11e8-8a3d-bae97d2c1afd_0

To get the process ID of either container, take note of the container ID or name, and use it in the following docker command:

docker inspect --format '{{ .State.Pid }}' container-id-or-name
Output
14552
A process ID (or PID) will be output. Now we can use the nsenter program to run a command in that process’s network namespace:

nsenter -t your-container-pid -n ip addr
Be sure to use your own PID, and replace ip addr with the command you’d like to run inside the pod’s network namespace.

Note: One advantage of using nsenter to run commands in a pod’s namespace – versus using something like docker exec – is that you have access to all of the commands available on the node, instead of the typically limited set of commands installed in containers.
3)

we check whether the file /tmp/healthy exists, and if the command returns an exit code zero, the container will be marked as healthy; otherwise, it will be marked as unhealthy.
readinessProbe:
  initialDelaySeconds: 1
  periodSeconds: 5
  timeoutSeconds: 1
  successThreshold: 1
  failureThreshold: 1
  exec:
    command:
      - cat
      - /tmp/healthy
4)
Startup probes: Verify whether an application within a container has started. It is executed only at startup. If a container fails this probe, the container is killed and follows the restartPolicy for the pod. You can configure startup probes in the spec.containers.startupProbe attribute. A significant reason to include startup probes is because some legacy applications require additional startup time when first initialized, which can make it difficult to set liveness probe parameters. Make sure you use the same protocol as the application when you configure a startupProbe— and ensure the failureThreshold * periodSeconds is long enough to cover the worst case startup time. 

Readiness probes: Verify that a Docker container is ready to serve requests. If the probe returns a failed state, Kubernetes removes the IP address for the pod from the endpoints of all services. Readiness probes enable you to advise Kubernetes that a running container should not receive traffic until additional tasks are completed. Those tasks include loading files, warming caches, and establishing network connections. The location to configure readiness probes is in the spec.containers.readinessProbe attribute for the pod configuration. These probes must be run periodically, with that period defined by the periodSeconds attribute.

Liveness probes: Use these liveness checks to assess whether an application running in a container is in a healthy state. If the liveness probe fails, Kubernetes kills the container and attempts to restart it. Liveness probes are useful when you want to ensure your application is not experiencing deadlock or silently unresponsive. Deadlock is a situation when your container is not ready but the liveness probe is performing and it exceeds the failure threshold, because of a too short delay time. To mitigate this, you should use a startup probe and set your threshold high enough. Configure liveness probes in the spec.containers.livenessProbe code attribute of the pod configuration. Similar to readiness probes, liveness probes also run periodically.

5) https://kubesandclouds.com/2021-01-20-ksniff/

6) Karpenter binds the pod to new node that it provisioned. Karpenter eliminates the need to manage many different node groups. You can deploy n number of provisioners like below based on your needs https://kubesandclouds.com/2022-01-04-karpenter/
apiVersion: karpenter.sh/v1alpha5
kind: Provisioner
metadata:
  name: default
spec:
  requirements:
    - key: karpenter.sh/capacity-type
      operator: In
      values: ["spot"]
  limits:
    resources:
      cpu: 1000
  provider:
    instanceProfile: KarpenterNodeInstanceProfile-${CLUSTER_NAME}
  ttlSecondsAfterEmpty: 30


